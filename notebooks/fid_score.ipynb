{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'calculate_frechet_distance' from 'pytorch_fid' (/root/miniconda3/envs/anomaly_detection/lib/python3.8/site-packages/pytorch_fid/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_fid\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_fid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_frechet_distance\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'calculate_frechet_distance' from 'pytorch_fid' (/root/miniconda3/envs/anomaly_detection/lib/python3.8/site-packages/pytorch_fid/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pytorch_fid\n",
    "from pytorch_fid import calculate_frechet_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_stats_from_act(act):\n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "\n",
    "    return mu, sigma\n",
    "\n",
    "def get_fid_from_act(act1, act2):\n",
    "    m1, s1 = get_stats_from_act(act1)\n",
    "    m2, s2 = get_stats_from_act(act2)\n",
    "\n",
    "    fid_value = calculate_frechet_distance(m1, s1, m2, s2)\n",
    "\n",
    "    return fid_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractor.utils import extract_features\n",
    "import json, os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# backbone = \"medsam\"\n",
    "# backbone = \"optimus_old\"\n",
    "# backbone = \"resnet50\"\n",
    "backbone = \"optimus\"\n",
    "input_path = \"/mnt/dataset/MoNuSeg/\"\n",
    "\n",
    "syn_dirs = [\n",
    "    \"/mnt/dataset/MoNuSeg/out_sdm_128x128/patches_valid_128.32CH_1000st_1e-4lr_8bs_hvb_col_cos_clus6/output_model*\"\n",
    "]\n",
    "\n",
    "feat_dirs = {\n",
    "    'train' : os.path.join(input_path, f\"patches_valid_inst_128x128_128x128/MoNuSegTrainingData/images_feat_{backbone}.json\"),\n",
    "    'test' : os.path.join(input_path, f\"patches_valid_inst_128x128_128x128/MoNuSegTestData/images_feat_{backbone}.json\"),\n",
    "    'v1.3' : os.path.join(input_path, f\"out_sdm_128x128/patches_valid_128.32CH_1000st_1e-4lr_8bs_hvb_col_cos_clus6/v1.3_feat_{backbone}.json\")\n",
    "}\n",
    "\n",
    "\n",
    "features_dict = {}\n",
    "\n",
    "for k, v in feat_dirs.items():\n",
    "    feat_path = v\n",
    "    # feat_path = k + f\"_feat_{backbone}.json\"\n",
    "\n",
    "    assert os.path.exists(feat_path), f\"Path doesn't exist: {feat_path}\"\n",
    "\n",
    "    with open(feat_path, 'r') as f:\n",
    "        feat_json = json.load(f)\n",
    "\n",
    "        # print(feat_json.keys())\n",
    "\n",
    "        opt_feat_flat = [feat_json[i] for i in images[k]]\n",
    "        opt_feat_flat = np.array(list(opt_feat_flat))  \n",
    "\n",
    "        print(feat_path, opt_feat_flat.shape)        \n",
    "\n",
    "        features_dict[k] = opt_feat_flat\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_extractor.utils import extract_features\n",
    "import json, os\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# backbone = \"medsam\"\n",
    "# backbone = \"optimus_old\"\n",
    "# backbone = \"resnet50\"\n",
    "backbone = \"optimus\"\n",
    "\n",
    "feat_dirs = {\n",
    "    'train' : os.path.join(input_path, f\"patches_valid_inst_128x128_128x128/MoNuSegTrainingData/images_feat_{backbone}.json\"),\n",
    "    'test' : os.path.join(input_path, f\"patches_valid_inst_128x128_128x128/MoNuSegTestData/images_feat_{backbone}.json\"),\n",
    "    'v1.3' : os.path.join(input_path, f\"out_sdm_128x128/patches_valid_128.32CH_1000st_1e-4lr_8bs_hvb_col_cos_clus6/v1.3_feat_{backbone}.json\")\n",
    "}\n",
    "\n",
    "\n",
    "features_dict = {}\n",
    "\n",
    "for k, v in feat_dirs.items():\n",
    "    feat_path = v\n",
    "    # feat_path = k + f\"_feat_{backbone}.json\"\n",
    "\n",
    "    assert os.path.exists(feat_path), f\"Path doesn't exist: {feat_path}\"\n",
    "\n",
    "    with open(feat_path, 'r') as f:\n",
    "        feat_json = json.load(f)\n",
    "\n",
    "        # print(feat_json.keys())\n",
    "\n",
    "        opt_feat_flat = [feat_json[i] for i in images[k]]\n",
    "        opt_feat_flat = np.array(list(opt_feat_flat))  \n",
    "\n",
    "        print(feat_path, opt_feat_flat.shape)        \n",
    "\n",
    "        features_dict[k] = opt_feat_flat\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
